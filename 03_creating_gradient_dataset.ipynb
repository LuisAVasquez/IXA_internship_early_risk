{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the topic model and the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(training_dir, \"topic_model.pk\"), \"rb\") as f:\n",
    "#    topic_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(training_dir, \"topics.pk\"), \"rb\") as f:\n",
    "    topics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(training_dir, \"training_probabilities.pk\"), \"rb\") as f:\n",
    "    probs = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# many probabilities are rounded to zero, \n",
    "# so, to calculate logits, we need to add a threshold\n",
    "from myutils.utils import LOGIT_THRESHOLD\n",
    "LOGIT_THRESHOLD # for smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs += LOGIT_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the logits using the natural logarithm\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999896315728952"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(2.718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_logits = log(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(training_dir, \"training_logits.pk\"), \"wb\") as f:\n",
    "    pickle.dump( training_logits, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating and annotating Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients are calculated as the difference in logits from one document to the next.\n",
    "\n",
    "Gradients are annotated with the same label as the user they come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training data\n",
    "import json\n",
    "from myutils.utils import using_downsampled_train_dataset\n",
    "\n",
    "if using_downsampled_train_dataset:\n",
    "    with open(\"./datasets/downsampled_train_dataset.json\", \"r\") as f:\n",
    "        train_dataset = json.load(f)\n",
    "else:\n",
    "    with open(\"./datasets/train_dataset.json\", \"r\") as f:\n",
    "        train_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'sfannah',\n",
       " 'labeled_texts': [{'text': \"wants mauds ice cream real bad   stupid england don't sell it\",\n",
       "   'polarity': 0},\n",
       "  {'text': 'is soo not ready for maths', 'polarity': 0},\n",
       "  {'text': 'has had terrible signal in culford so had not been on twitter or able to text',\n",
       "   'polarity': 0},\n",
       "  {'text': \"i have and you haven't replied\", 'polarity': 0},\n",
       "  {'text': 'i wish i could give you that hug right now', 'polarity': 0},\n",
       "  {'text': 'i secretly want to be a pokï¿½mon', 'polarity': 1},\n",
       "  {'text': 'its at home  i miss it', 'polarity': 0},\n",
       "  {'text': \"why is everyone watching f1 but me  i'm stuck watching parent trap... oh the joy!\",\n",
       "   'polarity': 0},\n",
       "  {'text': 'and this happens to be one of them', 'polarity': 1},\n",
       "  {'text': \"i don't think people would know how much that made me smile  i'm cheered up (y)\",\n",
       "   'polarity': 1},\n",
       "  {'text': 'thinks people should group hug more', 'polarity': 1},\n",
       "  {'text': 'sorry blame the phone!  me no means it', 'polarity': 0},\n",
       "  {'text': \":o not the iphone i'll do anything to save it anything you want please just don't hurt it  it's  red case is already cracked\",\n",
       "   'polarity': 0},\n",
       "  {'text': \"no  he's very clean i wanted to be able to say yes he's very dirty ;)\",\n",
       "   'polarity': 0},\n",
       "  {'text': \"actually i'm off to night guys   &amp; no it's not that's cheese &amp; nothing can beat my dream last night scary stuff\",\n",
       "   'polarity': 0},\n",
       "  {'text': ':s  wants to seee george or at least talk to him properly',\n",
       "   'polarity': 0},\n",
       "  {'text': 'course you did love... but  would have made it epic  pleaseee matt',\n",
       "   'polarity': 1},\n",
       "  {'text': \"needs to get changed then i'm ready\", 'polarity': 1},\n",
       "  {'text': 'lol speak for yourself  soo tired xxc', 'polarity': 0},\n",
       "  {'text': 'my iphone just said accept cookies? i was like hell yea!  i never got the cookies',\n",
       "   'polarity': 0},\n",
       "  {'text': \"okay i admit it i'm shttered\", 'polarity': 0},\n",
       "  {'text': 'you went to the sims 3 launch at gamer base without me?!',\n",
       "   'polarity': 0}],\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2391"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_gradients_for_training = []\n",
    "\n",
    "document_count = 0\n",
    "user_count = 0\n",
    "\n",
    "for entry in train_dataset:\n",
    "    new_entry = {}\n",
    "    new_entry.update(entry)\n",
    "    user_label =entry[\"label\"]\n",
    "\n",
    "\n",
    "    n_docs = len(entry[\"labeled_texts\"])\n",
    "    user_logits = training_logits[\n",
    "        document_count : document_count + n_docs\n",
    "    ]\n",
    "    user_gradients = [\n",
    "        list(next_logits - previous_logits)\n",
    "        for (previous_logits, next_logits)\n",
    "        in zip(\n",
    "            user_logits[0:n_docs-1], user_logits[1:n_docs]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # gradients inherit the user label, not the text polarity!\n",
    "    new_entry[\"labeled_gradients\"] = [\n",
    "        {\n",
    "            \"gradient\": list(gradi),\n",
    "            \"label\": user_label,\n",
    "        }\n",
    "        for gradi in user_gradients\n",
    "    ]\n",
    "\n",
    "    user_count +=1\n",
    "    document_count+=n_docs\n",
    "    labeled_gradients_for_training.append(new_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_gradients_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradient': [-2.39789527279837,\n",
       "  -2.39789527279837,\n",
       "  -2.39789527279837,\n",
       "  0.0,\n",
       "  -0.6466271649250519,\n",
       "  0.0,\n",
       "  -0.6808770879681312,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -1.0360919316867756,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4978384282391799,\n",
       "  -0.8873031950009036,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -1.570598079117837,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3894647667617237,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  -0.3894647667617237,\n",
       "  -0.4978384282391799,\n",
       "  -0.6690496289808854,\n",
       "  -0.4978384282391799,\n",
       "  0.0,\n",
       "  -0.6768866596881651,\n",
       "  -0.21825356602001822,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  0.0,\n",
       "  -0.8286926725561692,\n",
       "  0.0,\n",
       "  0.5331106685554259,\n",
       "  -0.9604619501872929,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.8873031950009036,\n",
       "  -0.3894647667617237,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -1.7512681078733188,\n",
       "  0.0,\n",
       "  -2.6964606674075444,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.6690496289808854,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3308542443169893,\n",
       "  0.6768866596881651,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.4978384282391799,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3077496355025904,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.4978384282391799,\n",
       "  -0.3973017974690034,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.21825356602001822,\n",
       "  0.0,\n",
       "  0.17904823144898518,\n",
       "  -0.6690496289808854,\n",
       "  -0.5042466526679483,\n",
       "  -0.3894647667617237,\n",
       "  -0.3894647667617237,\n",
       "  -0.17904823144898518,\n",
       "  0.0,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  -0.6768866596881651,\n",
       "  0.0,\n",
       "  0.21825356602001822,\n",
       "  0.3308542443169893,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.21825356602001822,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  0.3973017974690034,\n",
       "  0.0,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3973017974690034,\n",
       "  0.0,\n",
       "  1.9763307457560253,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  -0.8873031950009036,\n",
       "  -0.8873031950009036,\n",
       "  0.0,\n",
       "  0.7972874398125418,\n",
       "  0.0,\n",
       "  -1.0663514264498888,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3999856423435384,\n",
       "  0.0,\n",
       "  -0.8873031950009036,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5491078103370075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.21825356602001822,\n",
       "  0.11641035184441062,\n",
       "  -0.5491078103370075,\n",
       "  0.0,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.8873031950009036,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.2795848622191617,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3308542443169893,\n",
       "  -0.3308542443169893,\n",
       "  0.2795848622191617,\n",
       "  0.2795848622191617,\n",
       "  -0.6690496289808854,\n",
       "  -0.3894647667617237,\n",
       "  0.0,\n",
       "  -0.3894647667617237,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2795848622191617,\n",
       "  -0.2795848622191617,\n",
       "  -0.6690496289808854,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.3894647667617237,\n",
       "  -0.6768866596881651,\n",
       "  0.0,\n",
       "  -0.3894647667617237,\n",
       "  0.0],\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_gradients_for_training[0][\"labeled_gradients\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the gradient arrays are very sparse. \n",
    "I use PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutils.utils import N_GRADIENT_COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_gradients = []\n",
    "\n",
    "for entry in labeled_gradients_for_training:\n",
    "    user_gradients = [\n",
    "        dic[\"gradient\"]\n",
    "        for dic in entry[\"labeled_gradients\"]\n",
    "    ]\n",
    "    all_training_gradients += user_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22413"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_training_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from myutils.utils import N_GRADIENT_COMPONENTS\n",
    "\n",
    "pca_reduction = PCA(\n",
    "    n_components=N_GRADIENT_COMPONENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.73 s, sys: 20.2 s, total: 27 s\n",
      "Wall time: 1.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(n_components=20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pca_reduction.fit(all_training_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open(os.path.join(training_dir, \"pca_reduction.pk\"), \"wb\") as f:\n",
    "    pickle.dump(pca_reduction,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scaled_training_gradients = pca_reduction.transform(\n",
    "    all_training_gradients\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22413, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scaled_training_gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_reduced_gradients_for_training = []\n",
    "\n",
    "document_count = 0\n",
    "user_count = 0\n",
    "\n",
    "for entry in labeled_gradients_for_training:\n",
    "    new_entry = {}\n",
    "    new_entry.update(entry)\n",
    "    user_label =entry[\"label\"]\n",
    "\n",
    "\n",
    "    n_docs = len(entry[\"labeled_texts\"])\n",
    "\n",
    "    user_reduced_gradients = all_scaled_training_gradients[\n",
    "        document_count : document_count + n_docs\n",
    "    ]\n",
    "\n",
    "    # gradients inherit the user label, not the text polarity!\n",
    "    new_entry[\"labeled_reduced_gradients\"] = [\n",
    "        {\n",
    "            \"reduced_gradient\": list(gradi),\n",
    "            \"label\": user_label,\n",
    "        }\n",
    "        for gradi in user_reduced_gradients\n",
    "    ]\n",
    "\n",
    "    user_count +=1\n",
    "    document_count+=n_docs\n",
    "    labeled_reduced_gradients_for_training.append(new_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduced_gradient': [2.8440679818556456,\n",
       "  2.608103924314116,\n",
       "  -1.4816889170857397,\n",
       "  -1.121766689497795,\n",
       "  -4.967322755437853,\n",
       "  1.8053913339787224,\n",
       "  0.6283579344076613,\n",
       "  0.7047822062907131,\n",
       "  1.9792394964200222,\n",
       "  -0.15551180287707114,\n",
       "  -0.37031140988710914,\n",
       "  -0.13041313040467628,\n",
       "  -0.9325245392118704,\n",
       "  -0.11451198568048084,\n",
       "  -0.7045756635652524,\n",
       "  0.09302408276935789,\n",
       "  -0.5332816819558618,\n",
       "  0.09452667449349066,\n",
       "  0.25658897015932874,\n",
       "  0.18461801047191642],\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_reduced_gradients_for_training[0][\"labeled_reduced_gradients\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/labeled_reduced_gradients_for_training.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        labeled_reduced_gradients_for_training,\n",
    "        f,\n",
    "        indent=2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ixavenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
